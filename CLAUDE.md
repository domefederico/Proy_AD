# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This is a **final project for Data Analysis course** focused on mushroom classification using the UCI Secondary Mushroom Dataset. The project objective is to **predict if a mushroom is edible or poisonous** based on physical characteristics using machine learning techniques.

### Project Deliverables

The final project requires:

1. **Report (PDF)** containing:
   - Title, team members, and index
   - Problem description
   - Dataset description
   - Exploratory analysis
   - Data preprocessing
   - Data analysis with visualizations
   - Predictive model construction
   - Results
   - Conclusions

2. **Presentation:** Max 10 minutes

3. **Code:** Python file (.py or .ipynb)

## Repository Structure

### Main Analysis Notebooks

**Complete Workflow (in order):**

1. **`AnalisisExploratorio.ipynb`** - Exploratory data analysis
   - Format verification of variables
   - Identifies data quality issues (nulls, duplicates, outliers, invalid values)
   - Statistical analysis of distributions
   - Documents all problems found in original dataset

2. **`Limpieza_Datos.ipynb`** - Complete data cleaning process
   - 8-step cleaning strategy
   - Handles invalid values, outliers, unexpected categorical codes
   - **⚠️ Imputation strategy (median/mode GLOBAL - NO data leakage)**
   - **Eliminates rows with null `class` (target variable)**
   - Generates `MushroomDataset_cleaned.csv` ready for modeling
   - Includes validation checklist (10 automated checks)

3. **`Analisis_Visualizaciones.ipynb`** - Visual analysis and patterns
   - Comprehensive visualizations of all variables
   - Distribution analysis by class (edible vs poisonous)
   - Correlation heatmaps and feature importance
   - Habitat and season pattern analysis
   - Identifies top predictive features

4. **`Modelo_Predictivo.ipynb`** - **COMPLETE PREDICTIVE MODEL** ✓
   - Compares 6 ML algorithms (Logistic Regression, Decision Tree, Random Forest, Gradient Boosting, SVM, KNN)
   - GridSearchCV hyperparameter optimization
   - **Best model: Random Forest (99.45% recall for poisonous class)**
   - Feature importance analysis
   - ROC curves and confusion matrices
   - Public health safety evaluation (false negatives analysis)
   - **32 false negatives, 18 false positives in test set**
   - **⚠️ UPDATED with dataset without data leakage (50,865 rows)**

5. **`Codigo.ipynb`** - Legacy notebook (may contain older analysis)

### Data Directory: `MushroomDataset/`

#### Original Data
- **`MushroomDataset.csv`** - Main dataset (61,079 rows × 21 columns)
  - 173 mushroom species × 353 hypothetical samples each
  - **Delimiter:** comma (`,`)
  - Contains data quality issues (see AnalisisExploratorio.ipynb and Limpieza_Datos.ipynb)

- `primary_data.csv` - Source data (173 species, one per row)
- `secondary_data.csv` - Alternative name/copy of main dataset

#### Cleaned Data
- **`MushroomDataset_cleaned.csv`** - Clean dataset ready for modeling
  - Generated by Limpieza_Datos.ipynb
  - **50,865 rows × 17 columns (83.28% of original data retained)**
  - 100% complete (no null values)
  - No outliers, no invalid values, no duplicates
  - **No data leakage** (target `class` never used for imputation)
  - **Delimiter:** semicolon (`;`)
  - **Use this file for predictive modeling**

#### Documentation
- `secondary_data_meta.txt` - Official UCI documentation
  - Variable definitions and encoding
  - **CRITICAL:** All categorical codes are single letters
- `primary_data_meta.txt` - Primary dataset documentation

## Dataset Details

The project uses **MushroomDataset.csv** as the main dataset (61,079 rows, 21 columns):

**Target Variable:**
- `class`: poisonous (p) or edible (e)

**Key Features:**
- 3 metrical variables: `cap-diameter` (cm), `stem-height` (cm), `stem-width` (mm)
- 17 nominal variables: cap characteristics (shape, surface, color), gill features, stem properties, veil attributes, ring type, habitat, season
- Many nominal variables use single-letter encodings (documented in metadata files)

**Important Notes:**
- **Original dataset (MushroomDataset.csv) uses comma (`,`) delimiter**
- **Cleaned dataset (MushroomDataset_cleaned.csv) uses semicolon (`;`) delimiter**
- Original contains NaN values in several columns (`gill-spacing`, `spore-print-color`, `veil-type`, etc.)
- Nominal values are single-letter codes - refer to metadata files for interpretation

## Data Quality Issues Identified

The original `MushroomDataset.csv` has significant quality issues (documented in `AnalisisExploratorio.ipynb` and `Limpieza_Datos.ipynb`):

### Critical Issues
1. **Variables with >85% null values** (4 variables):
   - `veil-type`: 95.07% nulls
   - `spore-print-color`: 90.13% nulls
   - `veil-color`: 88.48% nulls
   - `stem-root`: 85.21% nulls

2. **Invalid numeric values**:
   - `cap-diameter`: 611 rows (1.00%) with string 'invalid_value'

3. **Undocumented categorical codes**:
   - `cap-surface`: code 'd' not in metadata (4,234 rows, 6.93%)
   - `stem-root`: code 'f' not in metadata (1,013 rows, 1.66%)

4. **Extreme outliers**:
   - `cap-diameter` max: 623.40 cm (biologically impossible - 6 meter mushroom!)
   - `stem-width` max: 1,039.10 mm (over 1 meter thick)

5. **Duplicates**: 45 fully duplicated rows (0.07%)

6. **Multiple nulls per row**: 100% of rows have at least 2 null values

### Solution
All issues are addressed in `Limpieza_Datos.ipynb` which produces `MushroomDataset_cleaned.csv` (100% complete, validated dataset).

## Recommended Workflow

### For New Analysis
```
1. Understand data quality issues → AnalisisExploratorio.ipynb
2. Review cleaning strategy → Limpieza_Datos.ipynb
3. Explore patterns visually → Analisis_Visualizaciones.ipynb
4. Review predictive model → Modelo_Predictivo.ipynb
5. Use cleaned data for new experiments → Load MushroomDataset_cleaned.csv
```

### For Predictive Modeling

**The predictive model is complete!** See `Modelo_Predictivo.ipynb` for:
- Complete model comparison (6 algorithms)
- Best model: Random Forest with **99.45% recall** for poisonous class
- Feature importance analysis
- Safety evaluation (false negatives analysis)
- **⚠️ Model trained with corrected dataset (NO data leakage)**

**To use the cleaned dataset:**
```python
# CORRECT - Use cleaned data (semicolon delimiter)
df = pd.read_csv('MushroomDataset/MushroomDataset_cleaned.csv', sep=';')

# WRONG - Don't use original data directly for modeling
# df = pd.read_csv('MushroomDataset/MushroomDataset.csv')  # Has quality issues
```

## Running Notebooks

**Primary workflow:**
```bash
jupyter notebook
# Opens browser interface to run .ipynb files
```

**Recommended execution order:**
1. `AnalisisExploratorio.ipynb` - Identify data quality issues
2. `Limpieza_Datos.ipynb` - Generate clean dataset
3. `Analisis_Visualizaciones.ipynb` - Visual pattern analysis
4. `Modelo_Predictivo.ipynb` - Complete predictive model (already done)

**To convert notebooks to Python scripts:**
```bash
jupyter nbconvert --to script AnalisisExploratorio.ipynb
jupyter nbconvert --to script Limpieza_Datos.ipynb
jupyter nbconvert --to script Modelo_Predictivo.ipynb
```

**Required imports:**
```python
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
```

## Data Loading

### Loading Original Data (for exploration only)
```python
# Original dataset uses COMMA delimiter
df = pd.read_csv('MushroomDataset/MushroomDataset.csv', low_memory=False)
# or
df = pd.read_csv('MushroomDataset/secondary_data.csv', low_memory=False)
```

### Loading Cleaned Data (for modeling)
```python
# Cleaned dataset uses SEMICOLON delimiter
df = pd.read_csv('MushroomDataset/MushroomDataset_cleaned.csv', sep=';')
```

**CRITICAL:**
- Original dataset (`MushroomDataset.csv`): uses **comma (`,`)** delimiter
- Cleaned dataset (`MushroomDataset_cleaned.csv`): uses **semicolon (`;`)** delimiter

## Variable Encoding Reference

When working with nominal variables, decode using metadata files:
- **Colors:** brown=n, buff=b, gray=g, green=r, pink=p, purple=u, red=e, white=w, yellow=y, blue=l, orange=o, black=k
- **Cap shapes:** bell=b, conical=c, convex=x, flat=f, sunken=s, spherical=p, others=o
- **Habitat:** grasses=g, leaves=l, meadows=m, paths=p, heaths=h, urban=u, waste=w, woods=d
- **Season:** spring=s, summer=u, autumn=a, winter=w

**IMPORTANT:** ALL categorical variables use **single-letter codes**. Any value with more than 1 character is an error.

Full encoding details are in `MushroomDataset/*_meta.txt` files.

## Data Cleaning Strategy Summary

The cleaning process in `Limpieza_Datos.ipynb` follows this order (CRITICAL - do not change):

```
1. Eliminate duplicates → Remove 45 rows
2. Eliminate variables with >85% nulls → Remove 4 columns
3. Handle 'invalid_value' in cap-diameter → Convert to numeric (NaN)
4. Eliminate unexpected categorical values → Remove ~4,200 rows
5. Eliminate extreme outliers (IQR × 3) → Remove ~3,200 rows
5.5. ⚠️ ELIMINATE rows with null 'class' → Remove ~2,700 rows (NO impute target)
6. Impute remaining nulls → Median/mode GLOBAL (SIN usar 'class' - NO data leakage)
7. Eliminate rows with >10 nulls → Remove any remaining incomplete rows
7.5. Eliminate duplicates (final) → Remove duplicates created by column removal
8. Reset index → Clean 0 to N-1
```

### ⚠️ CRITICAL: Data Leakage Prevention

**The variable `class` is NEVER used for imputation:**
- `class` is the target variable (what we want to predict)
- Using `class` to impute features would create data leakage
- Rows with null `class` are ELIMINATED (not imputed)
- All feature imputation uses GLOBAL median/mode (not grouped by class)

### Key Decisions

| Problem | Solution | Justification |
|---------|----------|---------------|
| Variables with >85% nulls | **ELIMINATE** | Imputing >85% generates synthetic data |
| 'invalid_value' (1% of data) | Convert to NaN, then **IMPUTE** median global | Only 1%, preserves valuable rows |
| Undocumented codes 'd' and 'f' | **ELIMINATE** rows | Incorrect data worse than less data |
| Outliers (6m diameter mushroom) | **ELIMINATE** (IQR × 3) | Biologically impossible |
| **⚠️ Null `class` values** | **ELIMINATE** rows (NO impute) | **Target variable - prevents data leakage** |
| Remaining nulls | **IMPUTE** median/mode GLOBAL (NOT by class) | **Prevents data leakage** |
| Duplicates | **ELIMINATE** | Prevents data leakage and inflation |

### Validation Checklist

After running `Limpieza_Datos.ipynb`, verify:
- ✓ No 'invalid_value' strings
- ✓ cap-diameter is numeric (float64)
- ✓ Zero null values (100% complete)
- ✓ No outliers >100cm or >200mm
- ✓ No undocumented categorical codes
- ✓ No duplicates
- ✓ Clean index (0 to N-1)
- ✓ >50% of original data retained
- ✓ Balanced classes (~50/50 e/p)

## Common Pitfalls to Avoid

1. **Don't use original data for modeling** - Always use `MushroomDataset_cleaned.csv`

2. **Don't confuse delimiters** - Original uses `,`, cleaned uses `;`

3. **Don't change the cleaning order** - Steps depend on each other (e.g., outliers must be removed BEFORE imputation)

4. **Don't impute variables with >85% nulls** - This creates more synthetic than real data

5. **Don't assume categorical codes** - Always check `secondary_data_meta.txt` for official encoding

6. **⚠️ NEVER use 'class' for imputation** - This creates data leakage. Use GLOBAL median/mode instead

## Project Status and Completion

Current status: ✅ **MODELING COMPLETE**

### Completed:
1. ✅ Exploratory data analysis (`AnalisisExploratorio.ipynb`)
2. ✅ Data cleaning (`Limpieza_Datos.ipynb`)
3. ✅ Visual analysis (`Analisis_Visualizaciones.ipynb`)
4. ✅ Feature engineering and encoding (`Modelo_Predictivo.ipynb`)
5. ✅ Train/test split (80/20) with stratification
6. ✅ Built 6 predictive models (LR, DT, RF, GB, SVM, KNN)
7. ✅ Hyperparameter optimization with GridSearchCV
8. ✅ Model evaluation (accuracy, precision, recall, F1, ROC-AUC)
9. ✅ Feature importance analysis
10. ✅ Safety evaluation (false negatives analysis)

### Best Model Results (UPDATED - No Data Leakage):
- **Algorithm:** Random Forest (optimized)
- **Dataset:** 50,865 rows (83.28% of original, NO data leakage)
- **Accuracy:** 99.51% (+0.24pp vs before)
- **Recall (poisonous class):** **99.45%** (CRITICAL metric) ✅ (+0.62pp vs before)
- **Precision:** 99.69%
- **F1-Score:** 99.57%
- **AUC-ROC:** 0.9998 (nearly perfect)
- **False Negatives:** 32 (0.55% of poisonous mushrooms) ✅ (-42 cases vs before)
- **False Positives:** 18 (0.41% of edible mushrooms)
- **Hyperparameters:** max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100

### Most Important Features (UPDATED):
1. stem-width (14.0%)
2. stem-height (8.6%)
3. gill-attachment (8.2%)
4. stem-color (7.8%)
5. cap-surface (7.7%)

### ⚠️ Note on Model Improvement:
**After correcting data leakage, the model IMPROVED:**
- Recall: 98.83% → 99.45% (+0.62pp)
- False Negatives: 74 → 32 cases (-56.8% reduction)
- AUC-ROC: 0.9980 → 0.9998
The 2,676 removed rows (with null `class`) contained noise that reduced generalization.

### TODO for Final Submission:
1. Write final report (PDF) - Include all analysis + model results
2. Prepare 10-minute presentation
3. Export final code (notebook or .py file)

## Questions or Issues?

If you encounter issues:
1. Check that you're using `MushroomDataset_cleaned.csv` (with `sep=';'`)
2. Verify delimiter: original uses `,`, cleaned uses `;`
3. Review the specific notebook's documentation
4. Check `secondary_data_meta.txt` for variable encoding
5. Ensure all validation checks pass in `Limpieza_Datos.ipynb`
6. For model questions, review `Modelo_Predictivo.ipynb` sections 1-10
