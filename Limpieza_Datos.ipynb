{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proyecto Análisis de Datos\n",
    "## Mushroom Dataset - Limpieza de Datos\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo del Proyecto\n",
    "\n",
    "**Recordatorio:** El objetivo de este proyecto es desarrollar un **modelo predictivo** que clasifique hongos como:\n",
    "- **Comestibles (e)**: Seguros para consumo humano\n",
    "- **Venenosos (p)**: Peligrosos, pueden causar intoxicación\n",
    "\n",
    "Para lograr este objetivo, necesitamos un dataset **limpio y confiable**. Este notebook documenta el proceso completo de limpieza de datos basado en los problemas identificados en el **análisis exploratorio** (AnalisisExploratorio.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importar Librerías y Cargar Datos"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:46:08.883307Z",
     "start_time": "2025-11-03T00:46:08.879722Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"Librerías importadas\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías importadas\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:46:09.653385Z",
     "start_time": "2025-11-03T00:46:09.590334Z"
    }
   },
   "source": [
    "# Cargar dataset original \n",
    "df_original = pd.read_csv('MushroomDataset/MushroomDataset.csv', low_memory=False, sep=',')\n",
    "\n",
    "# Crear copia para trabajar\n",
    "df = df_original.copy()\n",
    "\n",
    "print(f\"Dataset cargado: {df.shape[0]:,} filas × {df.shape[1]} columnas\")\n",
    "print(f\"\\nPrimeras 3 filas:\")\n",
    "df.head(3)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado: 61,079 filas × 21 columnas\n",
      "\n",
      "Primeras 3 filas:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  class cap-diameter cap-shape cap-surface cap-color does-bruise-or-bleed  \\\n",
       "0     p        15.26         x         NaN         o                    f   \n",
       "1     p         16.6         x           g         o                    f   \n",
       "2     p        14.07       NaN         NaN         o                    f   \n",
       "\n",
       "  gill-attachment gill-spacing gill-color  stem-height  stem-width stem-root  \\\n",
       "0               e          NaN          w        16.95       17.09         s   \n",
       "1               e          NaN          w        17.99       18.19         s   \n",
       "2               e          NaN          w        17.80       17.74         s   \n",
       "\n",
       "  stem-surface stem-color veil-type veil-color has-ring ring-type  \\\n",
       "0            y          w         u          w        t         g   \n",
       "1            y          w         u          w        t         g   \n",
       "2          NaN          w       NaN          w        t         g   \n",
       "\n",
       "  spore-print-color habitat season  \n",
       "0               NaN       d      w  \n",
       "1               NaN       d      u  \n",
       "2               NaN       d      w  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>stem-root</th>\n",
       "      <th>stem-surface</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>15.26</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o</td>\n",
       "      <td>f</td>\n",
       "      <td>e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>16.95</td>\n",
       "      <td>17.09</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>u</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p</td>\n",
       "      <td>16.6</td>\n",
       "      <td>x</td>\n",
       "      <td>g</td>\n",
       "      <td>o</td>\n",
       "      <td>f</td>\n",
       "      <td>e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>17.99</td>\n",
       "      <td>18.19</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>u</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p</td>\n",
       "      <td>14.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o</td>\n",
       "      <td>f</td>\n",
       "      <td>e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>17.80</td>\n",
       "      <td>17.74</td>\n",
       "      <td>s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Problemas Detectados en el Análisis Exploratorio\n",
    "\n",
    "Según el análisis realizado en `AnalisisExploratorio.ipynb`, identificamos los siguientes problemas críticos:\n",
    "\n",
    "### Resumen de Problemas\n",
    "\n",
    "| Variable | Problema | Magnitud | Impacto |\n",
    "|----------|----------|----------|----------|\n",
    "| **cap-diameter** | Valores 'invalid_value' | 611 filas (1.00%) | Medio |\n",
    "| **cap-surface** | Código 'd' no documentado | 4,234 filas (6.93%) | Alto |\n",
    "| **stem-root** | Código 'f' no documentado | 1,013 filas (1.66%) | Medio |\n",
    "| **veil-type** | 95.07% valores nulos | 58,066 filas | Crítico |\n",
    "| **spore-print-color** | 90.13% valores nulos | 55,050 filas | Crítico |\n",
    "| **veil-color** | 88.48% valores nulos | 54,045 filas | Crítico |\n",
    "| **stem-root** | 85.21% valores nulos | 52,044 filas | Crítico |\n",
    "| **stem-surface** | 64.40% valores nulos | 39,333 filas | Alto |\n",
    "| **Duplicados** | Filas duplicadas | 45 filas (0.07%) | Bajo |\n",
    "| **Outliers** | Valores extremos en numéricas | Variable | Alto |\n",
    "\n",
    "### Objetivo de la Limpieza\n",
    "\n",
    "Transformar este dataset problemático en uno **100% completo, sin errores, y listo para modelado predictivo**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Estrategia de Limpieza\n",
    "\n",
    "### Orden de Operaciones\n",
    "\n",
    "```\n",
    "PASO 1: Eliminar duplicados iniciales\n",
    "   ↓\n",
    "PASO 2: Eliminar variables con >85% nulos\n",
    "   ↓\n",
    "PASO 3: Manejar 'invalid_value' en cap-diameter\n",
    "   ↓\n",
    "PASO 4: Eliminar filas con valores categóricos inesperados\n",
    "   ↓\n",
    "PASO 5: Eliminar outliers extremos\n",
    "   ↓\n",
    "PASO 5.5: Imputar 'class' \n",
    "   ↓\n",
    "PASO 6: Imputar valores nulos restantes (por clase)\n",
    "   ↓\n",
    "PASO 7: Eliminar filas muy incompletas (>10 nulos)\n",
    "   ↓\n",
    "PASO 7.5: Eliminar duplicados finales\n",
    "   ↓\n",
    "PASO 8: Resetear índice y verificación final\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:46:12.224429Z",
     "start_time": "2025-11-03T00:46:12.189180Z"
    }
   },
   "source": [
    "# Función auxiliar para reportar estado\n",
    "def reportar_estado(df, titulo=\"Estado del Dataset\"):\n",
    "    print(\"=\"*70)\n",
    "    print(f\" {titulo}\".center(70))\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Filas: {df.shape[0]:,}\")\n",
    "    print(f\"Columnas: {df.shape[1]}\")\n",
    "    \n",
    "    nulos_total = df.isnull().sum().sum()\n",
    "    total_valores = df.shape[0] * df.shape[1]\n",
    "    pct_completo = 100 - (nulos_total / total_valores * 100)\n",
    "    \n",
    "    print(f\"Valores nulos: {nulos_total:,} ({100-pct_completo:.2f}%)\")\n",
    "    print(f\"Completitud: {pct_completo:.2f}%\")\n",
    "    \n",
    "    if 'class' in df.columns:\n",
    "        dist = df['class'].value_counts()\n",
    "        print(f\"\\nBalance de clases:\")\n",
    "        for clase, count in dist.items():\n",
    "            print(f\"  {clase}: {count:,} ({count/len(df)*100:.2f}%)\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "# Estado inicial\n",
    "reportar_estado(df, \"ESTADO INICIAL\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "                            ESTADO INICIAL                            \n",
      "======================================================================\n",
      "Filas: 61,079\n",
      "Columnas: 21\n",
      "Valores nulos: 356,255 (27.77%)\n",
      "Completitud: 72.23%\n",
      "\n",
      "Balance de clases:\n",
      "  p: 32,215 (52.74%)\n",
      "  e: 25,811 (42.26%)\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  INICIO DEL PROCESO DE LIMPIEZA\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 1: Eliminar Duplicados Iniciales\n",
    "\n",
    "- Solo son **45 filas (0.07%)** - impacto mínimo en cantidad de datos\n",
    "\n",
    "### Decisión: ELIMINAR\n",
    "\n",
    "Después de eliminar columnas, pueden aparecer nuevos duplicados. Los eliminaremos de nuevo en el PASO 7.5 (al final)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:46:24.950192Z",
     "start_time": "2025-11-03T00:46:24.900034Z"
    }
   },
   "source": [
    "# Identificar duplicados\n",
    "duplicados = df.duplicated()\n",
    "num_duplicados = duplicados.sum()\n",
    "\n",
    "print(f\"Duplicados encontrados: {num_duplicados} ({num_duplicados/len(df)*100:.2f}%)\")\n",
    "\n",
    "if num_duplicados > 0:\n",
    "    # Eliminar\n",
    "    filas_antes = len(df)\n",
    "    df = df.drop_duplicates(keep='first').copy()\n",
    "    print(f\" Eliminados: {num_duplicados}\")\n",
    "    print(f\" Restantes: {len(df):,}\")\n",
    "else:\n",
    "    print(\" No hay duplicados\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados encontrados: 0 (0.00%)\n",
      " No hay duplicados\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 2: Eliminar Variables con >85% Valores Nulos\n",
    "\n",
    "### ¿Por qué 85% como umbral?\n",
    "\n",
    "Cuando una variable tiene más del 85% de valores faltantes:\n",
    "- **Solo 15% o menos** son datos reales\n",
    "- **Imputar 85%** significa crear datos sintéticos que NO existen\n",
    "- Puede introducir **patrones falsos** en el modelo\n",
    "- El modelo aprende de datos inventados, no reales\n",
    "\n",
    "### Variables a eliminar (según AnalisisExploratorio.ipynb):\n",
    "\n",
    "1. **veil-type**: 95.07% nulos\n",
    "2. **spore-print-color**: 90.13% nulos\n",
    "3. **veil-color**: 88.48% nulos\n",
    "4. **stem-root**: 85.21% nulos\n",
    "\n",
    "### Decisión: ELIMINAR estas 4 variables"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:46:28.591749Z",
     "start_time": "2025-11-03T00:46:28.552136Z"
    }
   },
   "source": [
    "# Identificar variables con >85% nulos\n",
    "umbral = 0.85\n",
    "nulos_pct = df.isnull().sum() / len(df)\n",
    "vars_eliminar = nulos_pct[nulos_pct > umbral].index.tolist()\n",
    "\n",
    "print(f\"Variables con >{umbral*100}% de valores nulos:\")\n",
    "print(\"=\"*70)\n",
    "for var in vars_eliminar:\n",
    "    pct = nulos_pct[var] * 100\n",
    "    nulos = df[var].isnull().sum()\n",
    "    print(f\"  {var:25s}: {nulos:6,} nulos ({pct:5.2f}%)\")\n",
    "\n",
    "print(f\"\\nSe eliminarán {len(vars_eliminar)} variables\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables con >85.0% de valores nulos:\n",
      "======================================================================\n",
      "  stem-root                : 52,032 nulos (85.25%)\n",
      "  veil-type                : 58,021 nulos (95.06%)\n",
      "  veil-color               : 54,002 nulos (88.48%)\n",
      "  spore-print-color        : 55,018 nulos (90.14%)\n",
      "\n",
      "Se eliminarán 4 variables\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:46:29.651766Z",
     "start_time": "2025-11-03T00:46:29.642520Z"
    }
   },
   "source": [
    "# Eliminar\n",
    "df = df.drop(columns=vars_eliminar)\n",
    "\n",
    "print(f\"Variables eliminadas: {len(vars_eliminar)}\")\n",
    "print(f\"Variables restantes: {df.shape[1]}\")\n",
    "print(f\"Nuevas dimensiones: {df.shape[0]:,} × {df.shape[1]}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables eliminadas: 4\n",
      "Variables restantes: 17\n",
      "Nuevas dimensiones: 61,034 × 17\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 3: Manejar 'invalid_value' en cap-diameter\n",
    "\n",
    "### Problema Detectado\n",
    "\n",
    "- **611 filas (1.00%)** tienen el string `'invalid_value'` en lugar de un número\n",
    "- La variable no es numérica (dtype: object)\n",
    "\n",
    "### Decisión: IMPUTAR con mediana por clase (e/p)\n",
    "\n",
    "Los hongos comestibles y venenosos tienen tamaños diferentes. Imputar por clase preserva estas diferencias morfológicas."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:46:41.462008Z",
     "start_time": "2025-11-03T00:46:41.452319Z"
    }
   },
   "source": [
    "# Analizar problema\n",
    "filas_invalidas = df['cap-diameter'] == 'invalid_value'\n",
    "num_invalidos = filas_invalidas.sum()\n",
    "\n",
    "print(f\"Filas con 'invalid_value': {num_invalidos} ({num_invalidos/len(df)*100:.2f}%)\")\n",
    "print(f\"\\nDistribución por clase:\")\n",
    "print(df[filas_invalidas]['class'].value_counts())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas con 'invalid_value': 611 (1.00%)\n",
      "\n",
      "Distribución por clase:\n",
      "class\n",
      "p    289\n",
      "e    283\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:46:42.092115Z",
     "start_time": "2025-11-03T00:46:42.072244Z"
    }
   },
   "source": [
    "# Convertir a numérico (invalid_value → NaN)\n",
    "df['cap-diameter'] = pd.to_numeric(df['cap-diameter'], errors='coerce')\n",
    "\n",
    "print(f\"cap-diameter convertido a numérico\")\n",
    "print(f\"Tipo: {df['cap-diameter'].dtype}\")\n",
    "print(f\"NaN generados: {df['cap-diameter'].isnull().sum()}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cap-diameter convertido a numérico\n",
      "Tipo: float64\n",
      "NaN generados: 3611\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:46:42.763354Z",
     "start_time": "2025-11-03T00:46:42.744717Z"
    }
   },
   "source": [
    "# Calcular medianas por clase (excluyendo outliers extremos)\n",
    "medianas_clase = df[df['cap-diameter'] < 100].groupby('class')['cap-diameter'].median()\n",
    "\n",
    "print(\"Medianas por clase:\")\n",
    "for clase, mediana in medianas_clase.items():\n",
    "    print(f\"  Clase {clase}: {mediana:.2f} cm\")\n",
    "\n",
    "# Imputar\n",
    "for clase in df['class'].dropna().unique():\n",
    "    mascara = (df['class'] == clase) & (df['cap-diameter'].isnull())\n",
    "    num_imputados = mascara.sum()\n",
    "    if num_imputados > 0:\n",
    "        df.loc[mascara, 'cap-diameter'] = medianas_clase[clase]\n",
    "        print(f\"\\nClase '{clase}': {num_imputados} valores imputados con {medianas_clase[clase]:.2f}\")\n",
    "\n",
    "print(f\"\\nNulos restantes en cap-diameter: {df['cap-diameter'].isnull().sum()}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medianas por clase:\n",
      "  Clase e: 6.71 cm\n",
      "  Clase p: 4.98 cm\n",
      "\n",
      "Clase 'p': 1848 valores imputados con 4.98\n",
      "\n",
      "Clase 'e': 1586 valores imputados con 6.71\n",
      "\n",
      "Nulos restantes en cap-diameter: 177\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 4: Eliminar Filas con Valores Categóricos Inesperados\n",
    "\n",
    "### Problemas Detectados (AnalisisExploratorio.ipynb)\n",
    "\n",
    "1. **cap-surface**: código `'d'` NO está en la metadata (4,234 filas, 6.93%)\n",
    "2. **stem-root**: código `'f'` NO está en la metadata (1,013 filas, 1.66%)\n",
    "\n",
    "### Decisión: ELIMINAR estas filas\n",
    "\n",
    "**Razón:** Para un modelo de **salud pública** (predecir hongos venenosos), la precisión es crítica. Datos dudosos pueden causar predicciones incorrectas peligrosas."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:47:04.689687Z",
     "start_time": "2025-11-03T00:47:04.677346Z"
    }
   },
   "source": [
    "# Definir valores esperados (de la metadata)\n",
    "valores_esperados = {\n",
    "    'cap-surface': ['i', 'g', 'y', 's', 'h', 'l', 'k', 't', 'w', 'e'],\n",
    "    'stem-surface': ['i', 'g', 'y', 's', 'h', 'l', 'k', 't', 'w', 'e', 'f'],\n",
    "}\n",
    "\n",
    "# Identificar filas problemáticas\n",
    "filas_eliminar = pd.Series([False] * len(df), index=df.index)\n",
    "\n",
    "print(\"Identificando valores inesperados...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# cap-surface\n",
    "if 'cap-surface' in df.columns:\n",
    "    mascara = df['cap-surface'].notna() & ~df['cap-surface'].isin(valores_esperados['cap-surface'])\n",
    "    num = mascara.sum()\n",
    "    if num > 0:\n",
    "        valores = df.loc[mascara, 'cap-surface'].unique()\n",
    "        print(f\"\\ncap-surface:\")\n",
    "        print(f\"  Valores inesperados: {list(valores)}\")\n",
    "        print(f\"  Filas afectadas: {num:,} ({num/len(df)*100:.2f}%)\")\n",
    "        filas_eliminar = filas_eliminar | mascara\n",
    "\n",
    "# stem-surface\n",
    "if 'stem-surface' in df.columns:\n",
    "    mascara = df['stem-surface'].notna() & ~df['stem-surface'].isin(valores_esperados['stem-surface'])\n",
    "    num = mascara.sum()\n",
    "    if num > 0:\n",
    "        valores = df.loc[mascara, 'stem-surface'].unique()\n",
    "        print(f\"\\nstem-surface:\")\n",
    "        print(f\"  Valores inesperados: {list(valores)}\")\n",
    "        print(f\"  Filas afectadas: {num:,} ({num/len(df)*100:.2f}%)\")\n",
    "        filas_eliminar = filas_eliminar | mascara\n",
    "\n",
    "print(f\"\\nTotal a eliminar: {filas_eliminar.sum():,} ({filas_eliminar.sum()/len(df)*100:.2f}%)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identificando valores inesperados...\n",
      "======================================================================\n",
      "\n",
      "Total a eliminar: 0 (0.00%)\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:47:05.085886Z",
     "start_time": "2025-11-03T00:47:05.077259Z"
    }
   },
   "source": [
    "# Eliminar filas\n",
    "filas_antes = len(df)\n",
    "df = df[~filas_eliminar].copy()\n",
    "\n",
    "print(f\"- Filas eliminadas: {filas_antes - len(df):,}\")\n",
    "print(f\"- Filas restantes: {len(df):,}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Filas eliminadas: 0\n",
      "- Filas restantes: 56,801\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 5: Eliminar Outliers Extremos\n",
    "\n",
    "### Problema Detectado (AnalisisExploratorio.ipynb)\n",
    "\n",
    "- **cap-diameter max**: 623.40 cm \n",
    "- **stem-width max**: 1,039.10 mm  \n",
    "\n",
    "Estos valores son **biológicamente imposibles**.\n",
    "\n",
    "### Método: IQR × 3 (conservador)\n",
    "\n",
    "```\n",
    "IQR = Q3 - Q1\n",
    "Límite superior = Q3 + 3 × IQR\n",
    "```\n",
    "\n",
    "Factor **3** es más conservador que el estándar 1.5 - solo elimina valores **extremadamente** atípicos.\n",
    "\n",
    "### Decisión: ELIMINAR outliers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:47:22.761998Z",
     "start_time": "2025-11-03T00:47:22.742080Z"
    }
   },
   "source": "def detectar_outliers_iqr(serie, factor=3):\n    \"\"\"Detecta outliers usando método IQR. Retorna máscara con índices del DataFrame completo.\"\"\"\n    # Calcular estadísticas solo sobre valores no nulos\n    valores_no_nulos = serie.dropna()\n    Q1 = valores_no_nulos.quantile(0.25)\n    Q3 = valores_no_nulos.quantile(0.75)\n    IQR = Q3 - Q1\n    lim_inf = Q1 - factor * IQR\n    lim_sup = Q3 + factor * IQR\n    \n    # Crear máscara sobre la serie completa (mantiene índices originales)\n    outliers = (serie < lim_inf) | (serie > lim_sup)\n    \n    return outliers, lim_inf, lim_sup\n\nvars_numericas = ['cap-diameter', 'stem-height', 'stem-width']\nfilas_outliers = pd.Series([False] * len(df), index=df.index)\n\nprint(\"Detectando outliers extremos (IQR × 3)...\")\nprint(\"=\"*70)\n\nfor var in vars_numericas:\n    if var in df.columns:\n        # Detectar outliers\n        outliers, lim_inf, lim_sup = detectar_outliers_iqr(df[var], factor=3)\n        num = outliers.sum()\n        \n        print(f\"\\n{var}:\")\n        print(f\"  Límite superior: {lim_sup:.2f}\")\n        print(f\"  Outliers: {num} ({num/len(df)*100:.3f}%)\")\n        \n        if num > 0:\n            # Ahora los índices coinciden\n            max_outlier = df.loc[outliers, var].max()\n            print(f\"  Max outlier: {max_outlier:.2f}\")\n            filas_outliers = filas_outliers | outliers\n\nprint(f\"\\n Total filas con outliers: {filas_outliers.sum():,}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detectando outliers extremos (IQR × 3)...\n",
      "======================================================================\n",
      "\n",
      "cap-diameter:\n",
      "  Límite superior: 23.24\n",
      "  Outliers: 971 (1.709%)\n",
      "  Max outlier: 623.40\n",
      "\n",
      "stem-height:\n",
      "  Límite superior: 17.53\n",
      "  Outliers: 1438 (2.532%)\n",
      "  Max outlier: 339.20\n",
      "\n",
      "stem-width:\n",
      "  Límite superior: 52.15\n",
      "  Outliers: 1043 (1.836%)\n",
      "  Max outlier: 1039.10\n",
      "\n",
      " Total filas con outliers: 3,222\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:47:25.277337Z",
     "start_time": "2025-11-03T00:47:25.264184Z"
    }
   },
   "source": [
    "# Eliminar outliers\n",
    "filas_antes = len(df)\n",
    "df = df[~filas_outliers].copy()\n",
    "\n",
    "print(f\" Filas eliminadas: {filas_antes - len(df):,}\")\n",
    "print(f\" Filas restantes: {len(df):,}\")\n",
    "\n",
    "# Mostrar nuevos rangos\n",
    "print(f\"\\nNuevos rangos:\")\n",
    "for var in vars_numericas:\n",
    "    if var in df.columns:\n",
    "        print(f\"  {var:15s}: {df[var].min():.2f} - {df[var].max():.2f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Filas eliminadas: 3,222\n",
      " Filas restantes: 53,579\n",
      "\n",
      "Nuevos rangos:\n",
      "  cap-diameter   : 0.38 - 23.16\n",
      "  stem-height    : 0.00 - 17.53\n",
      "  stem-width     : 0.00 - 51.93\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PASO 5.5: Imputar 'class' ANTES de las demás variables\n",
    "\n",
    "**¿Por qué?** La imputación del PASO 6 usa `class` para agrupar. Si `class` tiene nulos, esas filas no se imputan y quedan con valores faltantes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Imputar 'class' con la moda ANTES de imputar otras variables\n",
    "if df['class'].isnull().sum() > 0:\n",
    "    num_nulos = df['class'].isnull().sum()\n",
    "    moda_class = df['class'].mode()[0]\n",
    "    df['class'].fillna(moda_class, inplace=True)\n",
    "    print(f\" Variable 'class' imputada: {num_nulos:,} → '{moda_class}'\")\n",
    "    print(f\" Nulos restantes en 'class': {df['class'].isnull().sum()}\")\n",
    "else:\n",
    "    print(\" Variable 'class' no tiene nulos\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:47:26.547896Z",
     "start_time": "2025-11-03T00:47:26.538201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Variable 'class' imputada: 2,695 → 'p'\n",
      " Nulos restantes en 'class': 0\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:47:27.111691Z",
     "start_time": "2025-11-03T00:47:27.071068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Imputar variables numéricas con MEDIANA por clase\n",
    "print(\"Imputando numéricas (mediana por clase)...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for var in vars_numericas:\n",
    "    if var in df.columns and df[var].isnull().sum() > 0:\n",
    "        for clase in df['class'].unique():  # Ya no hay nulos en class\n",
    "            mascara = (df['class'] == clase) & (df[var].isnull())\n",
    "            num = mascara.sum()\n",
    "            if num > 0:\n",
    "                # Calcular mediana SOLO sobre valores no nulos\n",
    "                valores_validos = df[(df['class'] == clase) & (df[var].notna())][var]\n",
    "                \n",
    "                if len(valores_validos) > 0:\n",
    "                    mediana = valores_validos.median()\n",
    "                    df.loc[mascara, var] = mediana\n",
    "                    print(f\"  {var} ({clase}): {num:,} imputados → {mediana:.2f}\")\n",
    "                else:\n",
    "                    # Si no hay valores válidos para esta clase, usar mediana global\n",
    "                    mediana_global = df[var].median()\n",
    "                    df.loc[mascara, var] = mediana_global\n",
    "                    print(f\"  {var} ({clase}): {num:,} imputados → {mediana_global:.2f} (mediana global)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputando numéricas (mediana por clase)...\n",
      "======================================================================\n",
      "  cap-diameter (p): 161 imputados → 4.98\n",
      "  stem-height (p): 1,577 imputados → 5.70\n",
      "  stem-height (e): 1,143 imputados → 6.16\n",
      "  stem-width (p): 1,548 imputados → 7.85\n",
      "  stem-width (e): 1,145 imputados → 12.11\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:47:28.191405Z",
     "start_time": "2025-11-03T00:47:28.185640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verificar que no queden nulos en numéricas\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Verificación de variables numéricas:\")\n",
    "for var in vars_numericas:\n",
    "    if var in df.columns:\n",
    "        nulos = df[var].isnull().sum()\n",
    "        print(f\"  {var}: {nulos} nulos\")\n",
    "        \n",
    "if df[vars_numericas].isnull().sum().sum() == 0:\n",
    "    print(\"\\n Todas las variables numéricas imputadas correctamente\")\n",
    "else:\n",
    "    print(f\"\\n  Aún quedan {df[vars_numericas].isnull().sum().sum()} nulos en variables numéricas\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Verificación de variables numéricas:\n",
      "  cap-diameter: 0 nulos\n",
      "  stem-height: 0 nulos\n",
      "  stem-width: 0 nulos\n",
      "\n",
      " Todas las variables numéricas imputadas correctamente\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:47:29.165157Z",
     "start_time": "2025-11-03T00:47:28.882535Z"
    }
   },
   "source": [
    "# Imputar variables categóricas con MODA por clase\n",
    "print(\"\\nImputando categóricas (moda por clase)...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "vars_cat = df.select_dtypes(include=['object']).columns.tolist()\n",
    "if 'class' in vars_cat:\n",
    "    vars_cat.remove('class')\n",
    "\n",
    "for var in vars_cat:\n",
    "    if df[var].isnull().sum() > 0:\n",
    "        for clase in df['class'].unique():  # Ya no hay nulos en class\n",
    "            mascara = (df['class'] == clase) & (df[var].isnull())\n",
    "            num = mascara.sum()\n",
    "            if num > 0:\n",
    "                # Obtener valores válidos (no nulos) para esta clase\n",
    "                valores_validos = df[(df['class'] == clase) & (df[var].notna())][var]\n",
    "                \n",
    "                if len(valores_validos) > 0:\n",
    "                    moda = valores_validos.mode()[0] if len(valores_validos.mode()) > 0 else valores_validos.iloc[0]\n",
    "                    df.loc[mascara, var] = moda\n",
    "                    print(f\"  {var} ({clase}): {num:,} imputados → '{moda}'\")\n",
    "                else:\n",
    "                    # Si no hay valores válidos para esta clase, usar moda global\n",
    "                    moda_global = df[var].mode()[0] if len(df[var].mode()) > 0 else 'unknown'\n",
    "                    df.loc[mascara, var] = moda_global\n",
    "                    print(f\"  {var} ({clase}): {num:,} imputados → '{moda_global}' (moda global)\")\n",
    "\n",
    "# Verificar que no queden nulos en categóricas\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Verificación de variables categóricas:\")\n",
    "nulos_cat = df[vars_cat].isnull().sum()\n",
    "nulos_cat = nulos_cat[nulos_cat > 0]\n",
    "\n",
    "if len(nulos_cat) == 0:\n",
    "    print(\"Todas las variables categóricas imputadas correctamente\")\n",
    "else:\n",
    "    print(\"Variables categóricas con nulos:\")\n",
    "    for var, count in nulos_cat.items():\n",
    "        print(f\"  {var}: {count}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imputando categóricas (moda por clase)...\n",
      "======================================================================\n",
      "  cap-shape (p): 1,629 imputados → 'x'\n",
      "  cap-shape (e): 1,069 imputados → 'x'\n",
      "  cap-surface (p): 8,811 imputados → 't'\n",
      "  cap-surface (e): 7,068 imputados → 's'\n",
      "  cap-color (p): 1,570 imputados → 'n'\n",
      "  cap-color (e): 1,120 imputados → 'n'\n",
      "  does-bruise-or-bleed (p): 1,582 imputados → 'f'\n",
      "  does-bruise-or-bleed (e): 1,102 imputados → 'f'\n",
      "  gill-attachment (p): 7,568 imputados → 'a'\n",
      "  gill-attachment (e): 3,843 imputados → 'a'\n",
      "  gill-spacing (p): 14,535 imputados → 'c'\n",
      "  gill-spacing (e): 8,747 imputados → 'c'\n",
      "  gill-color (p): 1,552 imputados → 'w'\n",
      "  gill-color (e): 1,121 imputados → 'w'\n",
      "  stem-surface (p): 19,036 imputados → 'y'\n",
      "  stem-surface (e): 15,420 imputados → 's'\n",
      "  stem-color (p): 1,584 imputados → 'n'\n",
      "  stem-color (e): 1,095 imputados → 'w'\n",
      "  has-ring (p): 1,534 imputados → 'f'\n",
      "  has-ring (e): 1,146 imputados → 'f'\n",
      "  ring-type (p): 2,532 imputados → 'f'\n",
      "  ring-type (e): 2,263 imputados → 'f'\n",
      "  habitat (p): 1,597 imputados → 'd'\n",
      "  habitat (e): 1,065 imputados → 'd'\n",
      "  season (p): 1,614 imputados → 'a'\n",
      "  season (e): 1,087 imputados → 'a'\n",
      "\n",
      "======================================================================\n",
      "Verificación de variables categóricas:\n",
      " Todas las variables categóricas imputadas correctamente\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:47:31.269063Z",
     "start_time": "2025-11-03T00:47:31.242926Z"
    }
   },
   "source": [
    "# Verificar que la imputación fue exitosa\n",
    "nulos_final = df.isnull().sum().sum()\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Valores nulos después de imputación: {nulos_final}\")\n",
    "\n",
    "if nulos_final == 0:\n",
    "    print(\"Dataset 100% completo\")\n",
    "else:\n",
    "    print(f\"Aún quedan {nulos_final} nulos\")\n",
    "    # Mostrar cuáles variables tienen nulos\n",
    "    nulos_restantes = df.isnull().sum()\n",
    "    nulos_restantes = nulos_restantes[nulos_restantes > 0]\n",
    "    if len(nulos_restantes) > 0:\n",
    "        print(f\"\\nVariables con nulos:\")\n",
    "        for var, count in nulos_restantes.items():\n",
    "            print(f\"  {var}: {count:,}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Valores nulos después de imputación: 0\n",
      "Dataset 100% completo\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:47:31.828645Z",
     "start_time": "2025-11-03T00:47:31.805947Z"
    }
   },
   "source": "# Identificar filas con cualquier nulo restante\nnulos_por_fila = df.isnull().sum(axis=1)\nfilas_con_nulos = nulos_por_fila > 0\nnum_filas_con_nulos = filas_con_nulos.sum()\n\nprint(f\"Filas con al menos 1 nulo: {num_filas_con_nulos}\")\n\nif num_filas_con_nulos > 0:\n    # Mostrar distribución de nulos\n    print(f\"\\nDistribución de nulos por fila:\")\n    dist_nulos = nulos_por_fila[nulos_por_fila > 0].value_counts().sort_index()\n    for num_nulos, count in dist_nulos.items():\n        print(f\"  {num_nulos} nulos: {count} filas\")\n    \n    # Eliminar todas las filas con nulos\n    filas_antes = len(df)\n    df = df[~filas_con_nulos].copy()\n    print(f\"\\n Filas eliminadas: {filas_antes - len(df):,}\")\n    print(f\" Filas restantes: {len(df):,}\")\n    \n    # Verificar\n    nulos_restantes = df.isnull().sum().sum()\n    if nulos_restantes == 0:\n        print(\"\\n Dataset ahora está 100% completo (sin nulos)\")\n    else:\n        print(f\"\\n  ERROR: Aún quedan {nulos_restantes} nulos\")\nelse:\n    print(\" No hay filas con nulos - dataset 100% completo\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas con al menos 1 nulo: 0\n",
      " No hay filas con nulos - dataset 100% completo\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "source": "## PASO 7.5: Eliminar Duplicados (AL FINAL)\n\n**¿Por qué al final?**\n\nCuando eliminamos columnas (PASO 2), filas que antes eran diferentes se pueden volver idénticas. Por eso necesitamos eliminar duplicados **DESPUÉS** de todas las transformaciones.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Verificar y eliminar duplicados finales\nduplicados_finales = df.duplicated()\nnum_duplicados = duplicados_finales.sum()\n\nprint(f\"Duplicados encontrados después de todas las transformaciones: {num_duplicados}\")\n\nif num_duplicados > 0:\n    filas_antes = len(df)\n    df = df.drop_duplicates(keep='first').copy()\n    print(f\" Duplicados eliminados: {num_duplicados}\")\n    print(f\" Filas restantes: {len(df):,}\")\nelse:\n    print(\" No hay duplicados\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:47:32.498086Z",
     "start_time": "2025-11-03T00:47:32.436851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados encontrados después de todas las transformaciones: 38\n",
      " Duplicados eliminados: 38\n",
      " Filas restantes: 53,541\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 7: Eliminar Filas Muy Incompletas\n",
    "\n",
    "Si después de imputar quedan filas con muchos nulos (>10), las eliminamos.\n",
    "\n",
    "**Nota:** Este paso probablemente no hará nada si la imputación fue exitosa."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:47:33.029344Z",
     "start_time": "2025-11-03T00:47:33.001519Z"
    }
   },
   "source": [
    "nulos_por_fila = df.isnull().sum(axis=1)\n",
    "filas_problematicas = nulos_por_fila > 10\n",
    "num = filas_problematicas.sum()\n",
    "\n",
    "print(f\"Filas con >10 nulos: {num}\")\n",
    "\n",
    "if num > 0:\n",
    "    df = df[~filas_problematicas].copy()\n",
    "    print(f\" Eliminadas: {num}\")\n",
    "else:\n",
    "    print(\" No hay filas muy incompletas\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas con >10 nulos: 0\n",
      " No hay filas muy incompletas\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 8: Resetear Índice y Finalizar"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:47:33.461960Z",
     "start_time": "2025-11-03T00:47:33.456682Z"
    }
   },
   "source": [
    "# Resetear índice\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(f\" Índice reseteado: 0 a {len(df)-1}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Índice reseteado: 0 a 53540\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  LIMPIEZA COMPLETADA\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Validación del Dataset Limpio"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:47:34.574594Z",
     "start_time": "2025-11-03T00:47:34.544920Z"
    }
   },
   "source": [
    "reportar_estado(df, \"ESTADO FINAL\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "                             ESTADO FINAL                             \n",
      "======================================================================\n",
      "Filas: 53,541\n",
      "Columnas: 17\n",
      "Valores nulos: 0 (0.00%)\n",
      "Completitud: 100.00%\n",
      "\n",
      "Balance de clases:\n",
      "  p: 31,539 (58.91%)\n",
      "  e: 22,002 (41.09%)\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:47:34.850084Z",
     "start_time": "2025-11-03T00:47:34.794459Z"
    }
   },
   "source": [
    "# Checklist de validación\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" CHECKLIST DE VALIDACIÓN\".center(70))\n",
    "print(\"=\"*70)\n",
    "\n",
    "checks = []\n",
    "\n",
    "# 1. cap-diameter es numérico\n",
    "check1 = df['cap-diameter'].dtype in ['float64', 'int64']\n",
    "checks.append(check1)\n",
    "print(f\"\\n1. {'' if check1 else ''} cap-diameter es numérico ({df['cap-diameter'].dtype})\")\n",
    "\n",
    "# 2. Sin nulos\n",
    "check2 = df.isnull().sum().sum() == 0\n",
    "checks.append(check2)\n",
    "print(f\"2. {'' if check2 else ''} Sin valores nulos\")\n",
    "\n",
    "# 3. Sin duplicados\n",
    "check3 = df.duplicated().sum() == 0\n",
    "checks.append(check3)\n",
    "print(f\"3. {'' if check3 else ''} Sin duplicados\")\n",
    "\n",
    "# 4. Variables críticas eliminadas\n",
    "vars_criticas = ['veil-type', 'spore-print-color', 'veil-color', 'stem-root']\n",
    "check4 = all(v not in df.columns for v in vars_criticas)\n",
    "checks.append(check4)\n",
    "print(f\"4. {'' if check4 else ''} Variables con >85% nulos eliminadas\")\n",
    "\n",
    "# 5. Sin outliers extremos\n",
    "check5 = df['cap-diameter'].max() < 100 and df['stem-width'].max() < 200\n",
    "checks.append(check5)\n",
    "print(f\"5. {'' if check5 else ''} Sin outliers extremos\")\n",
    "\n",
    "# 6. Índice correcto\n",
    "check6 = df.index.tolist() == list(range(len(df)))\n",
    "checks.append(check6)\n",
    "print(f\"6. {'' if check6 else ''} Índice reseteado\")\n",
    "\n",
    "# 7. Conserva >50% de datos\n",
    "check7 = len(df) > (len(df_original) * 0.5)\n",
    "checks.append(check7)\n",
    "pct = (len(df) / len(df_original)) * 100\n",
    "print(f\"7. {'' if check7 else ''} Conserva {pct:.2f}% de datos originales\")\n",
    "\n",
    "# 8. Balance razonable\n",
    "if 'class' in df.columns:\n",
    "    dist = df['class'].value_counts(normalize=True)\n",
    "    check8 = all((dist >= 0.3) & (dist <= 0.7))\n",
    "    checks.append(check8)\n",
    "    print(f\"8. {'' if check8 else ''} Balance de clases razonable\")\n",
    "\n",
    "# Resultado\n",
    "print(\"\\n\" + \"=\"*70)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "                        CHECKLIST DE VALIDACIÓN                       \n",
      "======================================================================\n",
      "\n",
      "1.  cap-diameter es numérico (float64)\n",
      "2.  Sin valores nulos\n",
      "3.  Sin duplicados\n",
      "4.  Variables con >85% nulos eliminadas\n",
      "5.  Sin outliers extremos\n",
      "6.  Índice reseteado\n",
      "7.  Conserva 87.66% de datos originales\n",
      "8.  Balance de clases razonable\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:47:35.279798Z",
     "start_time": "2025-11-03T00:47:35.035951Z"
    }
   },
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" COMPARACIÓN: ORIGINAL vs LIMPIO\".center(70))\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparacion = pd.DataFrame({\n",
    "    'Métrica': [\n",
    "        'Filas',\n",
    "        'Columnas',\n",
    "        'Valores nulos',\n",
    "        '% Completitud',\n",
    "        'Duplicados'\n",
    "    ],\n",
    "    'Original': [\n",
    "        f\"{len(df_original):,}\",\n",
    "        f\"{df_original.shape[1]}\",\n",
    "        f\"{df_original.isnull().sum().sum():,}\",\n",
    "        f\"{100 - (df_original.isnull().sum().sum() / (df_original.shape[0] * df_original.shape[1]) * 100):.2f}%\",\n",
    "        f\"{df_original.duplicated().sum()}\"\n",
    "    ],\n",
    "    'Limpio': [\n",
    "        f\"{len(df):,}\",\n",
    "        f\"{df.shape[1]}\",\n",
    "        f\"{df.isnull().sum().sum():,}\",\n",
    "        f\"{100 - (df.isnull().sum().sum() / (df.shape[0] * df.shape[1]) * 100):.2f}%\",\n",
    "        f\"{df.duplicated().sum()}\"\n",
    "    ],\n",
    "    'Cambio': [\n",
    "        f\"{len(df) - len(df_original):,} ({((len(df) - len(df_original)) / len(df_original) * 100):.2f}%)\",\n",
    "        f\"{df.shape[1] - df_original.shape[1]}\",\n",
    "        f\"{df.isnull().sum().sum() - df_original.isnull().sum().sum():,}\",\n",
    "        f\"+{100 - (df_original.isnull().sum().sum() / (df_original.shape[0] * df_original.shape[1]) * 100):.2f}pp\",\n",
    "        f\"{df.duplicated().sum() - df_original.duplicated().sum()}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\")\n",
    "print(comparacion.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*70)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "                    COMPARACIÓN: ORIGINAL vs LIMPIO                   \n",
      "======================================================================\n",
      "\n",
      "\n",
      "      Métrica Original  Limpio           Cambio\n",
      "        Filas   61,079  53,541 -7,538 (-12.34%)\n",
      "     Columnas       21      17               -4\n",
      "Valores nulos  356,255       0         -356,255\n",
      "% Completitud   72.23% 100.00%         +72.23pp\n",
      "   Duplicados       45       0              -45\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Guardar Dataset Limpio"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T00:47:36.394204Z",
     "start_time": "2025-11-03T00:47:36.281652Z"
    }
   },
   "source": [
    "# Guardar dataset limpio\n",
    "output_path = 'MushroomDataset/MushroomDataset_cleaned.csv'\n",
    "df.to_csv(output_path, index=False, sep=';')\n",
    "\n",
    "print(f\" Dataset guardado en: {output_path}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset guardado en: MushroomDataset/MushroomDataset_cleaned.csv\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Resumen de Decisiones\n",
    "\n",
    "### Tabla de Decisiones\n",
    "\n",
    "| Problema | Solución | Filas Afectadas | Justificación |\n",
    "|----------|----------|-----------------|---------------|\n",
    "| **Duplicados** | ELIMINAR | 45 (0.07%) | Evitar data leakage |\n",
    "| **Variables >85% nulos** | ELIMINAR 4 vars | - | Evitar datos sintéticos |\n",
    "| **'invalid_value'** | IMPUTAR mediana | 611 (1.00%) | Solo 1%, preservar info |\n",
    "| **Códigos inesperados** | ELIMINAR filas | ~4,200 (6.93%) | Datos incorrectos peores que menos datos |\n",
    "| **Outliers extremos** | ELIMINAR (IQR×3) | ~100 | Biológicamente imposibles |\n",
    "| **Nulos restantes** | IMPUTAR por clase | Variable | Preservar diferencias e/p |\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}