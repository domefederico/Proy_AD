{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proyecto Análisis de Datos\n",
    "## Mushroom Dataset - Limpieza de Datos\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo del Proyecto\n",
    "\n",
    "**Recordatorio:** El objetivo de este proyecto es desarrollar un **modelo predictivo** que clasifique hongos como:\n",
    "- **Comestibles (e)**: Seguros para consumo humano\n",
    "- **Venenosos (p)**: Peligrosos, pueden causar intoxicación\n",
    "\n",
    "Para lograr este objetivo, necesitamos un dataset **limpio y confiable**. Este notebook documenta el proceso completo de limpieza de datos basado en los problemas identificados en el **análisis exploratorio** (AnalisisExploratorio.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importar Librerías y Cargar Datos"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:32:57.297085Z",
     "start_time": "2025-11-19T14:32:57.273064Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"Librerías importadas\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías importadas\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:32:57.361238Z",
     "start_time": "2025-11-19T14:32:57.297820Z"
    }
   },
   "source": [
    "# Cargar dataset original \n",
    "df_original = pd.read_csv('MushroomDataset/MushroomDataset.csv', low_memory=False, sep=',')\n",
    "\n",
    "# Crear copia para trabajar\n",
    "df = df_original.copy()\n",
    "\n",
    "print(f\"Dataset cargado: {df.shape[0]:,} filas × {df.shape[1]} columnas\")\n",
    "print(f\"\\nPrimeras 3 filas:\")\n",
    "df.head(3)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado: 61,079 filas × 21 columnas\n",
      "\n",
      "Primeras 3 filas:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  class cap-diameter cap-shape cap-surface cap-color does-bruise-or-bleed  \\\n",
       "0     p        15.26         x         NaN         o                    f   \n",
       "1     p         16.6         x           g         o                    f   \n",
       "2     p        14.07       NaN         NaN         o                    f   \n",
       "\n",
       "  gill-attachment gill-spacing gill-color  stem-height  stem-width stem-root  \\\n",
       "0               e          NaN          w        16.95       17.09         s   \n",
       "1               e          NaN          w        17.99       18.19         s   \n",
       "2               e          NaN          w        17.80       17.74         s   \n",
       "\n",
       "  stem-surface stem-color veil-type veil-color has-ring ring-type  \\\n",
       "0            y          w         u          w        t         g   \n",
       "1            y          w         u          w        t         g   \n",
       "2          NaN          w       NaN          w        t         g   \n",
       "\n",
       "  spore-print-color habitat season  \n",
       "0               NaN       d      w  \n",
       "1               NaN       d      u  \n",
       "2               NaN       d      w  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>stem-root</th>\n",
       "      <th>stem-surface</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>15.26</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o</td>\n",
       "      <td>f</td>\n",
       "      <td>e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>16.95</td>\n",
       "      <td>17.09</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>u</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p</td>\n",
       "      <td>16.6</td>\n",
       "      <td>x</td>\n",
       "      <td>g</td>\n",
       "      <td>o</td>\n",
       "      <td>f</td>\n",
       "      <td>e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>17.99</td>\n",
       "      <td>18.19</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>u</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p</td>\n",
       "      <td>14.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o</td>\n",
       "      <td>f</td>\n",
       "      <td>e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>17.80</td>\n",
       "      <td>17.74</td>\n",
       "      <td>s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Problemas Detectados en el Análisis Exploratorio\n",
    "\n",
    "Según el análisis realizado en `AnalisisExploratorio.ipynb`, identificamos los siguientes problemas críticos:\n",
    "\n",
    "### Resumen de Problemas\n",
    "\n",
    "| Variable | Problema | Magnitud | Impacto |\n",
    "|----------|----------|----------|----------|\n",
    "| **cap-diameter** | Valores 'invalid_value' | 611 filas (1.00%) | Medio |\n",
    "| **cap-surface** | Código 'd' no documentado | 4,234 filas (6.93%) | Alto |\n",
    "| **stem-root** | Código 'f' no documentado | 1,013 filas (1.66%) | Medio |\n",
    "| **veil-type** | 95.07% valores nulos | 58,066 filas | Crítico |\n",
    "| **spore-print-color** | 90.13% valores nulos | 55,050 filas | Crítico |\n",
    "| **veil-color** | 88.48% valores nulos | 54,045 filas | Crítico |\n",
    "| **stem-root** | 85.21% valores nulos | 52,044 filas | Crítico |\n",
    "| **stem-surface** | 64.40% valores nulos | 39,333 filas | Alto |\n",
    "| **Duplicados** | Filas duplicadas | 45 filas (0.07%) | Bajo |\n",
    "| **Outliers** | Valores extremos en numéricas | Variable | Alto |\n",
    "\n",
    "### Objetivo de la Limpieza\n",
    "\n",
    "Transformar este dataset problemático en uno **100% completo, sin errores, y listo para modelado predictivo**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Estrategia de Limpieza\n\n### Orden de Operaciones\n\n```\nPASO 1: Eliminar duplicados iniciales\n   ↓\nPASO 2: Eliminar variables con >85% nulos\n   ↓\nPASO 3: Manejar 'invalid_value' en cap-diameter\n   ↓\nPASO 4: Eliminar filas con valores categóricos inesperados\n   ↓\nPASO 5: Eliminar outliers extremos\n   ↓\nPASO 5.5: ⚠️ ELIMINAR filas donde 'class' sea nulo (NO imputar)\n   ↓\nPASO 6: Imputar valores nulos restantes (mediana/moda GLOBAL - SIN usar 'class')\n   ↓\nPASO 7: Eliminar filas muy incompletas (>10 nulos)\n   ↓\nPASO 7.5: Eliminar duplicados finales\n   ↓\nPASO 8: Resetear índice y verificación final\n```\n\n### ⚠️ IMPORTANTE: Prevención de Data Leakage\n\n**NO se usa la variable objetivo (`class`) para imputar features:**\n- La variable `class` es el target que queremos predecir\n- Usar `class` para imputar crearía data leakage\n- Filas con `class` nulo se ELIMINAN (no se imputan)\n- Imputación de features usa mediana/moda GLOBAL (no por clase)"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:32:57.389080Z",
     "start_time": "2025-11-19T14:32:57.361841Z"
    }
   },
   "source": [
    "# Función auxiliar para reportar estado\n",
    "def reportar_estado(df, titulo=\"Estado del Dataset\"):\n",
    "    print(\"=\"*70)\n",
    "    print(f\" {titulo}\".center(70))\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Filas: {df.shape[0]:,}\")\n",
    "    print(f\"Columnas: {df.shape[1]}\")\n",
    "    \n",
    "    nulos_total = df.isnull().sum().sum()\n",
    "    total_valores = df.shape[0] * df.shape[1]\n",
    "    pct_completo = 100 - (nulos_total / total_valores * 100)\n",
    "    \n",
    "    print(f\"Valores nulos: {nulos_total:,} ({100-pct_completo:.2f}%)\")\n",
    "    print(f\"Completitud: {pct_completo:.2f}%\")\n",
    "    \n",
    "    if 'class' in df.columns:\n",
    "        dist = df['class'].value_counts()\n",
    "        print(f\"\\nBalance de clases:\")\n",
    "        for clase, count in dist.items():\n",
    "            print(f\"  {clase}: {count:,} ({count/len(df)*100:.2f}%)\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "# Estado inicial\n",
    "reportar_estado(df, \"ESTADO INICIAL\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "                            ESTADO INICIAL                            \n",
      "======================================================================\n",
      "Filas: 61,079\n",
      "Columnas: 21\n",
      "Valores nulos: 356,255 (27.77%)\n",
      "Completitud: 72.23%\n",
      "\n",
      "Balance de clases:\n",
      "  p: 32,215 (52.74%)\n",
      "  e: 25,811 (42.26%)\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  INICIO DEL PROCESO DE LIMPIEZA\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 1: Eliminar Duplicados Iniciales\n",
    "\n",
    "- Solo son **45 filas (0.07%)** - impacto mínimo en cantidad de datos\n",
    "\n",
    "### Decisión: ELIMINAR\n",
    "\n",
    "Después de eliminar columnas, pueden aparecer nuevos duplicados. Los eliminaremos de nuevo en el PASO 7.5 (al final)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:32:57.475707Z",
     "start_time": "2025-11-19T14:32:57.391625Z"
    }
   },
   "source": [
    "# Identificar duplicados\n",
    "duplicados = df.duplicated()\n",
    "num_duplicados = duplicados.sum()\n",
    "\n",
    "print(f\"Duplicados encontrados: {num_duplicados} ({num_duplicados/len(df)*100:.2f}%)\")\n",
    "\n",
    "if num_duplicados > 0:\n",
    "    # Eliminar\n",
    "    filas_antes = len(df)\n",
    "    df = df.drop_duplicates(keep='first').copy()\n",
    "    print(f\" Eliminados: {num_duplicados}\")\n",
    "    print(f\" Restantes: {len(df):,}\")\n",
    "else:\n",
    "    print(\" No hay duplicados\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados encontrados: 45 (0.07%)\n",
      " Eliminados: 45\n",
      " Restantes: 61,034\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 2: Eliminar Variables con >85% Valores Nulos\n",
    "\n",
    "### ¿Por qué 85% como umbral?\n",
    "\n",
    "Cuando una variable tiene más del 85% de valores faltantes:\n",
    "- **Solo 15% o menos** son datos reales\n",
    "- **Imputar 85%** significa crear datos sintéticos que NO existen\n",
    "- Puede introducir **patrones falsos** en el modelo\n",
    "- El modelo aprende de datos inventados, no reales\n",
    "\n",
    "### Variables a eliminar (según AnalisisExploratorio.ipynb):\n",
    "\n",
    "1. **veil-type**: 95.07% nulos\n",
    "2. **spore-print-color**: 90.13% nulos\n",
    "3. **veil-color**: 88.48% nulos\n",
    "4. **stem-root**: 85.21% nulos\n",
    "\n",
    "### Decisión: ELIMINAR estas 4 variables"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:32:57.504506Z",
     "start_time": "2025-11-19T14:32:57.476396Z"
    }
   },
   "source": [
    "# Identificar variables con >85% nulos\n",
    "umbral = 0.85\n",
    "nulos_pct = df.isnull().sum() / len(df)\n",
    "vars_eliminar = nulos_pct[nulos_pct > umbral].index.tolist()\n",
    "\n",
    "print(f\"Variables con >{umbral*100}% de valores nulos:\")\n",
    "print(\"=\"*70)\n",
    "for var in vars_eliminar:\n",
    "    pct = nulos_pct[var] * 100\n",
    "    nulos = df[var].isnull().sum()\n",
    "    print(f\"  {var:25s}: {nulos:6,} nulos ({pct:5.2f}%)\")\n",
    "\n",
    "print(f\"\\nSe eliminarán {len(vars_eliminar)} variables\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables con >85.0% de valores nulos:\n",
      "======================================================================\n",
      "  stem-root                : 52,032 nulos (85.25%)\n",
      "  veil-type                : 58,021 nulos (95.06%)\n",
      "  veil-color               : 54,002 nulos (88.48%)\n",
      "  spore-print-color        : 55,018 nulos (90.14%)\n",
      "\n",
      "Se eliminarán 4 variables\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:32:57.512098Z",
     "start_time": "2025-11-19T14:32:57.505144Z"
    }
   },
   "source": [
    "# Eliminar\n",
    "df = df.drop(columns=vars_eliminar)\n",
    "\n",
    "print(f\"Variables eliminadas: {len(vars_eliminar)}\")\n",
    "print(f\"Variables restantes: {df.shape[1]}\")\n",
    "print(f\"Nuevas dimensiones: {df.shape[0]:,} × {df.shape[1]}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables eliminadas: 4\n",
      "Variables restantes: 17\n",
      "Nuevas dimensiones: 61,034 × 17\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 3: Manejar 'invalid_value' en cap-diameter\n",
    "\n",
    "### Problema Detectado\n",
    "\n",
    "- **611 filas (1.00%)** tienen el string `'invalid_value'` en lugar de un número\n",
    "- La variable no es numérica (dtype: object)\n",
    "\n",
    "### Decisión: IMPUTAR con mediana por clase (e/p)\n",
    "\n",
    "Los hongos comestibles y venenosos tienen tamaños diferentes. Imputar por clase preserva estas diferencias morfológicas."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:32:57.518599Z",
     "start_time": "2025-11-19T14:32:57.512804Z"
    }
   },
   "source": [
    "# Analizar problema\n",
    "filas_invalidas = df['cap-diameter'] == 'invalid_value'\n",
    "num_invalidos = filas_invalidas.sum()\n",
    "\n",
    "print(f\"Filas con 'invalid_value': {num_invalidos} ({num_invalidos/len(df)*100:.2f}%)\")\n",
    "print(f\"\\nDistribución por clase:\")\n",
    "print(df[filas_invalidas]['class'].value_counts())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas con 'invalid_value': 611 (1.00%)\n",
      "\n",
      "Distribución por clase:\n",
      "class\n",
      "p    289\n",
      "e    283\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:32:57.532708Z",
     "start_time": "2025-11-19T14:32:57.519214Z"
    }
   },
   "source": [
    "# Convertir a numérico (invalid_value → NaN)\n",
    "df['cap-diameter'] = pd.to_numeric(df['cap-diameter'], errors='coerce')\n",
    "\n",
    "print(f\"cap-diameter convertido a numérico\")\n",
    "print(f\"Tipo: {df['cap-diameter'].dtype}\")\n",
    "print(f\"NaN generados: {df['cap-diameter'].isnull().sum()}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cap-diameter convertido a numérico\n",
      "Tipo: float64\n",
      "NaN generados: 3611\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:32:57.553310Z",
     "start_time": "2025-11-19T14:32:57.533515Z"
    }
   },
   "source": [
    "# Calcular medianas por clase (excluyendo outliers extremos)\n",
    "medianas_clase = df[df['cap-diameter'] < 100].groupby('class')['cap-diameter'].median()\n",
    "\n",
    "print(\"Medianas por clase:\")\n",
    "for clase, mediana in medianas_clase.items():\n",
    "    print(f\"  Clase {clase}: {mediana:.2f} cm\")\n",
    "\n",
    "# Imputar\n",
    "for clase in df['class'].dropna().unique():\n",
    "    mascara = (df['class'] == clase) & (df['cap-diameter'].isnull())\n",
    "    num_imputados = mascara.sum()\n",
    "    if num_imputados > 0:\n",
    "        df.loc[mascara, 'cap-diameter'] = medianas_clase[clase]\n",
    "        print(f\"\\nClase '{clase}': {num_imputados} valores imputados con {medianas_clase[clase]:.2f}\")\n",
    "\n",
    "print(f\"\\nNulos restantes en cap-diameter: {df['cap-diameter'].isnull().sum()}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medianas por clase:\n",
      "  Clase e: 6.71 cm\n",
      "  Clase p: 4.98 cm\n",
      "\n",
      "Clase 'p': 1848 valores imputados con 4.98\n",
      "\n",
      "Clase 'e': 1586 valores imputados con 6.71\n",
      "\n",
      "Nulos restantes en cap-diameter: 177\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 4: Eliminar Filas con Valores Categóricos Inesperados\n",
    "\n",
    "### Problemas Detectados (AnalisisExploratorio.ipynb)\n",
    "\n",
    "1. **cap-surface**: código `'d'` NO está en la metadata (4,234 filas, 6.93%)\n",
    "2. **stem-root**: código `'f'` NO está en la metadata (1,013 filas, 1.66%)\n",
    "\n",
    "### Decisión: ELIMINAR estas filas\n",
    "\n",
    "**Razón:** Para un modelo de **salud pública** (predecir hongos venenosos), la precisión es crítica. Datos dudosos pueden causar predicciones incorrectas peligrosas."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:32:57.566309Z",
     "start_time": "2025-11-19T14:32:57.554003Z"
    }
   },
   "source": [
    "# Definir valores esperados (de la metadata)\n",
    "valores_esperados = {\n",
    "    'cap-surface': ['i', 'g', 'y', 's', 'h', 'l', 'k', 't', 'w', 'e'],\n",
    "    'stem-surface': ['i', 'g', 'y', 's', 'h', 'l', 'k', 't', 'w', 'e', 'f'],\n",
    "}\n",
    "\n",
    "# Identificar filas problemáticas\n",
    "filas_eliminar = pd.Series([False] * len(df), index=df.index)\n",
    "\n",
    "print(\"Identificando valores inesperados...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# cap-surface\n",
    "if 'cap-surface' in df.columns:\n",
    "    mascara = df['cap-surface'].notna() & ~df['cap-surface'].isin(valores_esperados['cap-surface'])\n",
    "    num = mascara.sum()\n",
    "    if num > 0:\n",
    "        valores = df.loc[mascara, 'cap-surface'].unique()\n",
    "        print(f\"\\ncap-surface:\")\n",
    "        print(f\"  Valores inesperados: {list(valores)}\")\n",
    "        print(f\"  Filas afectadas: {num:,} ({num/len(df)*100:.2f}%)\")\n",
    "        filas_eliminar = filas_eliminar | mascara\n",
    "\n",
    "# stem-surface\n",
    "if 'stem-surface' in df.columns:\n",
    "    mascara = df['stem-surface'].notna() & ~df['stem-surface'].isin(valores_esperados['stem-surface'])\n",
    "    num = mascara.sum()\n",
    "    if num > 0:\n",
    "        valores = df.loc[mascara, 'stem-surface'].unique()\n",
    "        print(f\"\\nstem-surface:\")\n",
    "        print(f\"  Valores inesperados: {list(valores)}\")\n",
    "        print(f\"  Filas afectadas: {num:,} ({num/len(df)*100:.2f}%)\")\n",
    "        filas_eliminar = filas_eliminar | mascara\n",
    "\n",
    "print(f\"\\nTotal a eliminar: {filas_eliminar.sum():,} ({filas_eliminar.sum()/len(df)*100:.2f}%)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identificando valores inesperados...\n",
      "======================================================================\n",
      "\n",
      "cap-surface:\n",
      "  Valores inesperados: ['d']\n",
      "  Filas afectadas: 4,233 (6.94%)\n",
      "\n",
      "Total a eliminar: 4,233 (6.94%)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:32:57.582504Z",
     "start_time": "2025-11-19T14:32:57.566950Z"
    }
   },
   "source": [
    "# Eliminar filas\n",
    "filas_antes = len(df)\n",
    "df = df[~filas_eliminar].copy()\n",
    "\n",
    "print(f\"- Filas eliminadas: {filas_antes - len(df):,}\")\n",
    "print(f\"- Filas restantes: {len(df):,}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Filas eliminadas: 4,233\n",
      "- Filas restantes: 56,801\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 5: Eliminar Outliers Extremos\n",
    "\n",
    "### Problema Detectado (AnalisisExploratorio.ipynb)\n",
    "\n",
    "- **cap-diameter max**: 623.40 cm \n",
    "- **stem-width max**: 1,039.10 mm  \n",
    "\n",
    "Estos valores son **biológicamente imposibles**.\n",
    "\n",
    "### Método: IQR × 3 (conservador)\n",
    "\n",
    "```\n",
    "IQR = Q3 - Q1\n",
    "Límite superior = Q3 + 3 × IQR\n",
    "```\n",
    "\n",
    "Factor **3** es más conservador que el estándar 1.5 - solo elimina valores **extremadamente** atípicos.\n",
    "\n",
    "### Decisión: ELIMINAR outliers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:32:57.597247Z",
     "start_time": "2025-11-19T14:32:57.583369Z"
    }
   },
   "source": "def detectar_outliers_iqr(serie, factor=3):\n    \"\"\"Detecta outliers usando método IQR. Retorna máscara con índices del DataFrame completo.\"\"\"\n    # Calcular estadísticas solo sobre valores no nulos\n    valores_no_nulos = serie.dropna()\n    Q1 = valores_no_nulos.quantile(0.25)\n    Q3 = valores_no_nulos.quantile(0.75)\n    IQR = Q3 - Q1\n    lim_inf = Q1 - factor * IQR\n    lim_sup = Q3 + factor * IQR\n    \n    # Crear máscara sobre la serie completa (mantiene índices originales)\n    outliers = (serie < lim_inf) | (serie > lim_sup)\n    \n    return outliers, lim_inf, lim_sup\n\nvars_numericas = ['cap-diameter', 'stem-height', 'stem-width']\nfilas_outliers = pd.Series([False] * len(df), index=df.index)\n\nprint(\"Detectando outliers extremos (IQR × 3)...\")\nprint(\"=\"*70)\n\nfor var in vars_numericas:\n    if var in df.columns:\n        # Detectar outliers\n        outliers, lim_inf, lim_sup = detectar_outliers_iqr(df[var], factor=3)\n        num = outliers.sum()\n        \n        print(f\"\\n{var}:\")\n        print(f\"  Límite superior: {lim_sup:.2f}\")\n        print(f\"  Outliers: {num} ({num/len(df)*100:.3f}%)\")\n        \n        if num > 0:\n            # Ahora los índices coinciden\n            max_outlier = df.loc[outliers, var].max()\n            print(f\"  Max outlier: {max_outlier:.2f}\")\n            filas_outliers = filas_outliers | outliers\n\nprint(f\"\\n Total filas con outliers: {filas_outliers.sum():,}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detectando outliers extremos (IQR × 3)...\n",
      "======================================================================\n",
      "\n",
      "cap-diameter:\n",
      "  Límite superior: 23.24\n",
      "  Outliers: 971 (1.709%)\n",
      "  Max outlier: 623.40\n",
      "\n",
      "stem-height:\n",
      "  Límite superior: 17.53\n",
      "  Outliers: 1438 (2.532%)\n",
      "  Max outlier: 339.20\n",
      "\n",
      "stem-width:\n",
      "  Límite superior: 52.15\n",
      "  Outliers: 1043 (1.836%)\n",
      "  Max outlier: 1039.10\n",
      "\n",
      " Total filas con outliers: 3,222\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:32:57.609670Z",
     "start_time": "2025-11-19T14:32:57.597975Z"
    }
   },
   "source": [
    "# Eliminar outliers\n",
    "filas_antes = len(df)\n",
    "df = df[~filas_outliers].copy()\n",
    "\n",
    "print(f\" Filas eliminadas: {filas_antes - len(df):,}\")\n",
    "print(f\" Filas restantes: {len(df):,}\")\n",
    "\n",
    "# Mostrar nuevos rangos\n",
    "print(f\"\\nNuevos rangos:\")\n",
    "for var in vars_numericas:\n",
    "    if var in df.columns:\n",
    "        print(f\"  {var:15s}: {df[var].min():.2f} - {df[var].max():.2f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Filas eliminadas: 3,222\n",
      " Filas restantes: 53,579\n",
      "\n",
      "Nuevos rangos:\n",
      "  cap-diameter   : 0.38 - 23.16\n",
      "  stem-height    : 0.00 - 17.53\n",
      "  stem-width     : 0.00 - 51.93\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": "## PASO 5.5: ELIMINAR Filas con 'class' Nulo\n\n**CRÍTICO:** La variable `class` es nuestro target (variable objetivo). Si tiene valores nulos, **NO podemos imputarlos** porque:\n- Sería **data leakage** usar `class` para imputar features\n- No podemos entrenar un modelo sin saber la etiqueta verdadera\n\n**Decisión: ELIMINAR** todas las filas donde `class` sea nulo.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# ELIMINAR filas donde 'class' sea nulo (NO imputar)\n",
    "if df['class'].isnull().sum() > 0:\n",
    "    num_nulos = df['class'].isnull().sum()\n",
    "    filas_antes = len(df)\n",
    "    \n",
    "    # Eliminar filas\n",
    "    df = df[df['class'].notna()].copy()\n",
    "    \n",
    "    print(f\"Variable 'class' (TARGET) con nulos: {num_nulos:,}\")\n",
    "    print(f\"Filas eliminadas: {num_nulos:,}\")\n",
    "    print(f\"Filas restantes: {len(df):,}\")\n",
    "    print(f\"Nulos restantes en 'class': {df['class'].isnull().sum()}\")\n",
    "else:\n",
    "    print(\"Variable 'class' no tiene nulos\")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:32:57.626030Z",
     "start_time": "2025-11-19T14:32:57.610415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Variable 'class' (TARGET) con nulos: 2,695\n",
      "✓ Filas eliminadas: 2,695\n",
      "✓ Filas restantes: 50,884\n",
      "✓ Nulos restantes en 'class': 0\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:32:57.634914Z",
     "start_time": "2025-11-19T14:32:57.628090Z"
    }
   },
   "cell_type": "code",
   "source": "# Imputar variables numéricas con MEDIANA GLOBAL (NO por clase - evitar data leakage)\nprint(\"Imputando numéricas (mediana global - SIN usar 'class')...\")\nprint(\"=\"*70)\n\nfor var in vars_numericas:\n    if var in df.columns and df[var].isnull().sum() > 0:\n        num_nulos = df[var].isnull().sum()\n        \n        # Calcular mediana GLOBAL sobre valores no nulos\n        mediana_global = df[var].median()\n        \n        # Imputar\n        df[var].fillna(mediana_global, inplace=True)\n        \n        print(f\"  {var}: {num_nulos:,} imputados → {mediana_global:.2f} (mediana global)\")\n\n# Verificar\nprint(f\"\\n✓ Nulos restantes en numéricas: {df[vars_numericas].isnull().sum().sum()}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputando numéricas (mediana global - SIN usar 'class')...\n",
      "======================================================================\n",
      "  stem-height: 2,577 imputados → 5.93 (mediana global)\n",
      "  stem-width: 2,563 imputados → 9.99 (mediana global)\n",
      "\n",
      "✓ Nulos restantes en numéricas: 0\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:32:57.988245Z",
     "start_time": "2025-11-19T14:32:57.984225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verificar que no queden nulos en numéricas\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Verificación de variables numéricas:\")\n",
    "for var in vars_numericas:\n",
    "    if var in df.columns:\n",
    "        nulos = df[var].isnull().sum()\n",
    "        print(f\"  {var}: {nulos} nulos\")\n",
    "        \n",
    "if df[vars_numericas].isnull().sum().sum() == 0:\n",
    "    print(\"\\n Todas las variables numéricas imputadas correctamente\")\n",
    "else:\n",
    "    print(f\"\\n  Aún quedan {df[vars_numericas].isnull().sum().sum()} nulos en variables numéricas\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Verificación de variables numéricas:\n",
      "  cap-diameter: 0 nulos\n",
      "  stem-height: 0 nulos\n",
      "  stem-width: 0 nulos\n",
      "\n",
      " Todas las variables numéricas imputadas correctamente\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:32:58.557744Z",
     "start_time": "2025-11-19T14:32:58.459492Z"
    }
   },
   "source": [
    "# Imputar variables categóricas con MODA GLOBAL (NO por clase - evitar data leakage)\n",
    "print(\"\\nImputando categóricas (moda global - SIN usar 'class')...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "vars_cat = df.select_dtypes(include=['object']).columns.tolist()\n",
    "if 'class' in vars_cat:\n",
    "    vars_cat.remove('class')\n",
    "\n",
    "for var in vars_cat:\n",
    "    if df[var].isnull().sum() > 0:\n",
    "        num_nulos = df[var].isnull().sum()\n",
    "        \n",
    "        # Calcular moda GLOBAL sobre valores no nulos\n",
    "        valores_validos = df[var].dropna()\n",
    "        \n",
    "        if len(valores_validos) > 0:\n",
    "            moda_global = valores_validos.mode()[0]\n",
    "            df[var].fillna(moda_global, inplace=True)\n",
    "            print(f\"  {var}: {num_nulos:,} imputados → '{moda_global}' (moda global)\")\n",
    "        else:\n",
    "            print(f\"  {var}: {num_nulos:,} - NO SE PUDO IMPUTAR (sin valores válidos)\")\n",
    "\n",
    "# Verificar que no queden nulos en categóricas\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Verificación de variables categóricas:\")\n",
    "nulos_cat = df[vars_cat].isnull().sum()\n",
    "nulos_cat = nulos_cat[nulos_cat > 0]\n",
    "\n",
    "if len(nulos_cat) == 0:\n",
    "    print(\"Todas las variables categóricas imputadas correctamente\")\n",
    "else:\n",
    "    print(\"Variables categóricas con nulos:\")\n",
    "    for var, count in nulos_cat.items():\n",
    "        print(f\"  {var}: {count}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Imputando categóricas (moda global - SIN usar 'class')...\n",
      "======================================================================\n",
      "  cap-shape: 2,570 imputados → 'x' (moda global)\n",
      "  cap-surface: 15,105 imputados → 't' (moda global)\n",
      "  cap-color: 2,552 imputados → 'n' (moda global)\n",
      "  does-bruise-or-bleed: 2,533 imputados → 'f' (moda global)\n",
      "  gill-attachment: 10,812 imputados → 'a' (moda global)\n",
      "  gill-spacing: 22,067 imputados → 'c' (moda global)\n",
      "  gill-color: 2,545 imputados → 'w' (moda global)\n",
      "  stem-surface: 32,782 imputados → 's' (moda global)\n",
      "  stem-color: 2,555 imputados → 'w' (moda global)\n",
      "  has-ring: 2,553 imputados → 'f' (moda global)\n",
      "  ring-type: 4,549 imputados → 'f' (moda global)\n",
      "  habitat: 2,508 imputados → 'd' (moda global)\n",
      "  season: 2,567 imputados → 'a' (moda global)\n",
      "\n",
      "======================================================================\n",
      "Verificación de variables categóricas:\n",
      "✓ Todas las variables categóricas imputadas correctamente\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:32:58.940368Z",
     "start_time": "2025-11-19T14:32:58.922066Z"
    }
   },
   "source": [
    "# Verificar que la imputación fue exitosa\n",
    "nulos_final = df.isnull().sum().sum()\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Valores nulos después de imputación: {nulos_final}\")\n",
    "\n",
    "if nulos_final == 0:\n",
    "    print(\"Dataset 100% completo\")\n",
    "else:\n",
    "    print(f\"Aún quedan {nulos_final} nulos\")\n",
    "    # Mostrar cuáles variables tienen nulos\n",
    "    nulos_restantes = df.isnull().sum()\n",
    "    nulos_restantes = nulos_restantes[nulos_restantes > 0]\n",
    "    if len(nulos_restantes) > 0:\n",
    "        print(f\"\\nVariables con nulos:\")\n",
    "        for var, count in nulos_restantes.items():\n",
    "            print(f\"  {var}: {count:,}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Valores nulos después de imputación: 0\n",
      "Dataset 100% completo\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:32:59.395551Z",
     "start_time": "2025-11-19T14:32:59.373570Z"
    }
   },
   "source": "# Identificar filas con cualquier nulo restante\nnulos_por_fila = df.isnull().sum(axis=1)\nfilas_con_nulos = nulos_por_fila > 0\nnum_filas_con_nulos = filas_con_nulos.sum()\n\nprint(f\"Filas con al menos 1 nulo: {num_filas_con_nulos}\")\n\nif num_filas_con_nulos > 0:\n    # Mostrar distribución de nulos\n    print(f\"\\nDistribución de nulos por fila:\")\n    dist_nulos = nulos_por_fila[nulos_por_fila > 0].value_counts().sort_index()\n    for num_nulos, count in dist_nulos.items():\n        print(f\"  {num_nulos} nulos: {count} filas\")\n    \n    # Eliminar todas las filas con nulos\n    filas_antes = len(df)\n    df = df[~filas_con_nulos].copy()\n    print(f\"\\n Filas eliminadas: {filas_antes - len(df):,}\")\n    print(f\" Filas restantes: {len(df):,}\")\n    \n    # Verificar\n    nulos_restantes = df.isnull().sum().sum()\n    if nulos_restantes == 0:\n        print(\"\\n Dataset ahora está 100% completo (sin nulos)\")\n    else:\n        print(f\"\\n  ERROR: Aún quedan {nulos_restantes} nulos\")\nelse:\n    print(\" No hay filas con nulos - dataset 100% completo\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas con al menos 1 nulo: 0\n",
      " No hay filas con nulos - dataset 100% completo\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": "## PASO 7.5: Eliminar Duplicados (AL FINAL)\n\n**¿Por qué al final?**\n\nCuando eliminamos columnas (PASO 2), filas que antes eran diferentes se pueden volver idénticas. Por eso necesitamos eliminar duplicados **DESPUÉS** de todas las transformaciones.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Verificar y eliminar duplicados finales\nduplicados_finales = df.duplicated()\nnum_duplicados = duplicados_finales.sum()\n\nprint(f\"Duplicados encontrados después de todas las transformaciones: {num_duplicados}\")\n\nif num_duplicados > 0:\n    filas_antes = len(df)\n    df = df.drop_duplicates(keep='first').copy()\n    print(f\" Duplicados eliminados: {num_duplicados}\")\n    print(f\" Filas restantes: {len(df):,}\")\nelse:\n    print(\" No hay duplicados\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:33:00.340672Z",
     "start_time": "2025-11-19T14:33:00.289427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados encontrados después de todas las transformaciones: 31\n",
      " Duplicados eliminados: 31\n",
      " Filas restantes: 50,853\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 7: Eliminar Filas Muy Incompletas\n",
    "\n",
    "Si después de imputar quedan filas con muchos nulos (>10), las eliminamos.\n",
    "\n",
    "**Nota:** Este paso probablemente no hará nada si la imputación fue exitosa."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:33:01.205196Z",
     "start_time": "2025-11-19T14:33:01.184462Z"
    }
   },
   "source": [
    "nulos_por_fila = df.isnull().sum(axis=1)\n",
    "filas_problematicas = nulos_por_fila > 10\n",
    "num = filas_problematicas.sum()\n",
    "\n",
    "print(f\"Filas con >10 nulos: {num}\")\n",
    "\n",
    "if num > 0:\n",
    "    df = df[~filas_problematicas].copy()\n",
    "    print(f\" Eliminadas: {num}\")\n",
    "else:\n",
    "    print(\" No hay filas muy incompletas\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas con >10 nulos: 0\n",
      " No hay filas muy incompletas\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 8: Resetear Índice y Finalizar"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:33:02.236581Z",
     "start_time": "2025-11-19T14:33:02.232513Z"
    }
   },
   "source": [
    "# Resetear índice\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(f\" Índice reseteado: 0 a {len(df)-1}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Índice reseteado: 0 a 50852\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  LIMPIEZA COMPLETADA\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Validación del Dataset Limpio"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:33:03.869320Z",
     "start_time": "2025-11-19T14:33:03.850669Z"
    }
   },
   "source": [
    "reportar_estado(df, \"ESTADO FINAL\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "                             ESTADO FINAL                             \n",
      "======================================================================\n",
      "Filas: 50,853\n",
      "Columnas: 17\n",
      "Valores nulos: 0 (0.00%)\n",
      "Completitud: 100.00%\n",
      "\n",
      "Balance de clases:\n",
      "  p: 28,851 (56.73%)\n",
      "  e: 22,002 (43.27%)\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:33:04.365927Z",
     "start_time": "2025-11-19T14:33:04.316045Z"
    }
   },
   "source": [
    "# Checklist de validación\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" CHECKLIST DE VALIDACIÓN\".center(70))\n",
    "print(\"=\"*70)\n",
    "\n",
    "checks = []\n",
    "\n",
    "# 1. cap-diameter es numérico\n",
    "check1 = df['cap-diameter'].dtype in ['float64', 'int64']\n",
    "checks.append(check1)\n",
    "print(f\"\\n1. {'' if check1 else ''} cap-diameter es numérico ({df['cap-diameter'].dtype})\")\n",
    "\n",
    "# 2. Sin nulos\n",
    "check2 = df.isnull().sum().sum() == 0\n",
    "checks.append(check2)\n",
    "print(f\"2. {'' if check2 else ''} Sin valores nulos\")\n",
    "\n",
    "# 3. Sin duplicados\n",
    "check3 = df.duplicated().sum() == 0\n",
    "checks.append(check3)\n",
    "print(f\"3. {'' if check3 else ''} Sin duplicados\")\n",
    "\n",
    "# 4. Variables críticas eliminadas\n",
    "vars_criticas = ['veil-type', 'spore-print-color', 'veil-color', 'stem-root']\n",
    "check4 = all(v not in df.columns for v in vars_criticas)\n",
    "checks.append(check4)\n",
    "print(f\"4. {'' if check4 else ''} Variables con >85% nulos eliminadas\")\n",
    "\n",
    "# 5. Sin outliers extremos\n",
    "check5 = df['cap-diameter'].max() < 100 and df['stem-width'].max() < 200\n",
    "checks.append(check5)\n",
    "print(f\"5. {'' if check5 else ''} Sin outliers extremos\")\n",
    "\n",
    "# 6. Índice correcto\n",
    "check6 = df.index.tolist() == list(range(len(df)))\n",
    "checks.append(check6)\n",
    "print(f\"6. {'' if check6 else ''} Índice reseteado\")\n",
    "\n",
    "# 7. Conserva >50% de datos\n",
    "check7 = len(df) > (len(df_original) * 0.5)\n",
    "checks.append(check7)\n",
    "pct = (len(df) / len(df_original)) * 100\n",
    "print(f\"7. {'' if check7 else ''} Conserva {pct:.2f}% de datos originales\")\n",
    "\n",
    "# 8. Balance razonable\n",
    "if 'class' in df.columns:\n",
    "    dist = df['class'].value_counts(normalize=True)\n",
    "    check8 = all((dist >= 0.3) & (dist <= 0.7))\n",
    "    checks.append(check8)\n",
    "    print(f\"8. {'' if check8 else ''} Balance de clases razonable\")\n",
    "\n",
    "# Resultado\n",
    "print(\"\\n\" + \"=\"*70)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "                        CHECKLIST DE VALIDACIÓN                       \n",
      "======================================================================\n",
      "\n",
      "1.  cap-diameter es numérico (float64)\n",
      "2.  Sin valores nulos\n",
      "3.  Sin duplicados\n",
      "4.  Variables con >85% nulos eliminadas\n",
      "5.  Sin outliers extremos\n",
      "6.  Índice reseteado\n",
      "7.  Conserva 83.26% de datos originales\n",
      "8.  Balance de clases razonable\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:33:05.153683Z",
     "start_time": "2025-11-19T14:33:04.917950Z"
    }
   },
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" COMPARACIÓN: ORIGINAL vs LIMPIO\".center(70))\n",
    "print(\"=\"*70)\n",
    "\n",
    "comparacion = pd.DataFrame({\n",
    "    'Métrica': [\n",
    "        'Filas',\n",
    "        'Columnas',\n",
    "        'Valores nulos',\n",
    "        '% Completitud',\n",
    "        'Duplicados'\n",
    "    ],\n",
    "    'Original': [\n",
    "        f\"{len(df_original):,}\",\n",
    "        f\"{df_original.shape[1]}\",\n",
    "        f\"{df_original.isnull().sum().sum():,}\",\n",
    "        f\"{100 - (df_original.isnull().sum().sum() / (df_original.shape[0] * df_original.shape[1]) * 100):.2f}%\",\n",
    "        f\"{df_original.duplicated().sum()}\"\n",
    "    ],\n",
    "    'Limpio': [\n",
    "        f\"{len(df):,}\",\n",
    "        f\"{df.shape[1]}\",\n",
    "        f\"{df.isnull().sum().sum():,}\",\n",
    "        f\"{100 - (df.isnull().sum().sum() / (df.shape[0] * df.shape[1]) * 100):.2f}%\",\n",
    "        f\"{df.duplicated().sum()}\"\n",
    "    ],\n",
    "    'Cambio': [\n",
    "        f\"{len(df) - len(df_original):,} ({((len(df) - len(df_original)) / len(df_original) * 100):.2f}%)\",\n",
    "        f\"{df.shape[1] - df_original.shape[1]}\",\n",
    "        f\"{df.isnull().sum().sum() - df_original.isnull().sum().sum():,}\",\n",
    "        f\"+{100 - (df_original.isnull().sum().sum() / (df_original.shape[0] * df_original.shape[1]) * 100):.2f}pp\",\n",
    "        f\"{df.duplicated().sum() - df_original.duplicated().sum()}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\")\n",
    "print(comparacion.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*70)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "                    COMPARACIÓN: ORIGINAL vs LIMPIO                   \n",
      "======================================================================\n",
      "\n",
      "\n",
      "      Métrica Original  Limpio            Cambio\n",
      "        Filas   61,079  50,853 -10,226 (-16.74%)\n",
      "     Columnas       21      17                -4\n",
      "Valores nulos  356,255       0          -356,255\n",
      "% Completitud   72.23% 100.00%          +72.23pp\n",
      "   Duplicados       45       0               -45\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Guardar Dataset Limpio"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T14:33:08.393964Z",
     "start_time": "2025-11-19T14:33:08.273802Z"
    }
   },
   "source": [
    "# Guardar dataset limpio\n",
    "output_path = 'MushroomDataset/MushroomDataset_cleaned.csv'\n",
    "df.to_csv(output_path, index=False, sep=';')\n",
    "\n",
    "print(f\" Dataset guardado en: {output_path}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset guardado en: MushroomDataset/MushroomDataset_cleaned.csv\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Resumen de Decisiones\n",
    "\n",
    "### Tabla de Decisiones\n",
    "\n",
    "| Problema | Solución | Filas Afectadas | Justificación |\n",
    "|----------|----------|-----------------|---------------|\n",
    "| **Duplicados** | ELIMINAR | 45 (0.07%) | Evitar data leakage |\n",
    "| **Variables >85% nulos** | ELIMINAR 4 vars | - | Evitar datos sintéticos |\n",
    "| **'invalid_value'** | IMPUTAR mediana global | 611 (1.00%) | Solo 1%, preservar info |\n",
    "| **Códigos inesperados** | ELIMINAR filas | ~4,200 (6.93%) | Datos incorrectos peores que menos datos |\n",
    "| **Outliers extremos** | ELIMINAR (IQR×3) | ~100 | Biológicamente imposibles |\n",
    "| **'class' nulos** | **ELIMINAR filas** | Variable | **NO imputar target - evitar data leakage** |\n",
    "| **Nulos restantes** | IMPUTAR mediana/moda GLOBAL | Variable | **SIN usar 'class' - evitar data leakage** |"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
